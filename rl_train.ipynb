{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\git\\rl_train\\.venv\\lib\\site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the environment\n",
    "class GuessingGame:\n",
    "    def __init__(self, target_number, max_attempts):\n",
    "        self.target_number = target_number\n",
    "        self.max_attempts = max_attempts\n",
    "        self.current_attempt = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_attempt = 0\n",
    "        return self.current_attempt\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.current_attempt += 1\n",
    "        if action == self.target_number:\n",
    "            reward = 10\n",
    "            done = True\n",
    "        elif self.current_attempt >= self.max_attempts:\n",
    "            reward = -10\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1\n",
    "            done = False\n",
    "        \n",
    "        return self.current_attempt, reward, done\n",
    "\n",
    "# Q-learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):\n",
    "        self.q_table = np.zeros((state_space, action_space))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.randint(0, self.q_table.shape[1] - 1)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.visits = 0\n",
    "        self.value = 0\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, env, num_simulations=100, exploration_constant=1.41):\n",
    "        self.env = env\n",
    "        self.num_simulations = num_simulations\n",
    "        self.exploration_constant = exploration_constant\n",
    "\n",
    "    def search(self, state):\n",
    "        root = MCTSNode(state)\n",
    "\n",
    "        for _ in range(self.num_simulations):\n",
    "            node = self.select(root)\n",
    "            reward = self.simulate(node.state)\n",
    "            self.backpropagate(node, reward)\n",
    "\n",
    "        return max(root.children.items(), key=lambda x: x[1].visits)[0]\n",
    "\n",
    "    def select(self, node):\n",
    "        while node.children:\n",
    "            if len(node.children) < 10:  # Not all actions have been tried\n",
    "                return self.expand(node)\n",
    "            else:\n",
    "                node = self.uct_select(node)\n",
    "        return self.expand(node)\n",
    "\n",
    "    def expand(self, node):\n",
    "        untried_actions = set(range(10)) - set(node.children.keys())\n",
    "        action = random.choice(list(untried_actions))\n",
    "        next_state, _, _ = self.env.step(action)\n",
    "        child = MCTSNode(next_state, parent=node)\n",
    "        node.children[action] = child\n",
    "        return child\n",
    "\n",
    "    def simulate(self, state):\n",
    "        current_state = state\n",
    "        while True:\n",
    "            action = random.randint(0, 9)\n",
    "            next_state, reward, done = self.env.step(action)\n",
    "            if done:\n",
    "                return reward\n",
    "            current_state = next_state\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += reward\n",
    "            node = node.parent\n",
    "\n",
    "    def uct_select(self, node):\n",
    "        log_n = math.log(node.visits)\n",
    "        return max(node.children.items(),\n",
    "                   key=lambda x: x[1].value / x[1].visits + self.exploration_constant * math.sqrt(log_n / x[1].visits))[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent is trying to guess the number 1\n",
      "Attempt 1: Agent guessed 2\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 2\n",
      "Attempt 1: Agent guessed 2\n",
      "Game finished. Total attempts: 1, Total reward: 10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 9\n",
      "Attempt 1: Agent guessed 8\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 4\n",
      "Attempt 1: Agent guessed 5\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 3\n",
      "Attempt 1: Agent guessed 0\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 5\n",
      "Attempt 1: Agent guessed 0\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 4\n",
      "Attempt 1: Agent guessed 8\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 6\n",
      "Attempt 1: Agent guessed 6\n",
      "Game finished. Total attempts: 1, Total reward: 10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 2\n",
      "Attempt 1: Agent guessed 7\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 5\n",
      "Attempt 1: Agent guessed 3\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 6\n",
      "Attempt 1: Agent guessed 7\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 4\n",
      "Attempt 1: Agent guessed 1\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 8\n",
      "Attempt 1: Agent guessed 0\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 6\n",
      "Attempt 1: Agent guessed 0\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 3\n",
      "Attempt 1: Agent guessed 7\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 2\n",
      "Attempt 1: Agent guessed 7\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n",
      "\n",
      "Agent is trying to guess the number 1\n",
      "Attempt 1: Agent guessed 4\n",
      "Game finished. Total attempts: 1, Total reward: -10\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Interactive testing loop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     target_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter a number for the agent to guess (0-9), or -1 to quit: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Interactive testing loop\n",
    "while True:\n",
    "    target_number = int(input(\"Enter a number for the agent to guess (0-9), or -1 to quit: \"))\n",
    "    if target_number == -1:\n",
    "        break\n",
    "    \n",
    "    env = GuessingGame(target_number, max_attempts=10)\n",
    "    mcts = MCTS(env)  # Create MCTS instance here\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    attempts = 0\n",
    "\n",
    "    print(f\"\\nAgent is trying to guess the number {target_number}\")\n",
    "    while not done:\n",
    "        action = mcts.search(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "        attempts += 1\n",
    "        print(f\"Attempt {attempts}: Agent guessed {action}\")\n",
    "        state = next_state\n",
    "\n",
    "    print(f\"Game finished. Total attempts: {attempts}, Total reward: {total_reward}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the trained agent:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting the trained agent:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m----> 8\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mget_action(state)\n\u001b[0;32m      9\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     10\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the trained agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing the trained agent:\")\n",
    "while not done:\n",
    "    action = agent.get_action(state)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(f\"Attempt {state + 1}: Guessed {action}\")\n",
    "    state = next_state\n",
    "\n",
    "print(f\"Game finished. Total reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
